{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "moral-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from utils import split_reservations\n",
    "from features import X1_cxl_cols, X2_cxl_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "polish-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 60\n",
    "pd.options.display.max_columns = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "novel-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_res = pd.read_pickle(\"pickle/h1_res.pick\")\n",
    "h2_res = pd.read_pickle(\"pickle/h2_res.pick\")\n",
    "h1_dbd = pd.read_pickle(\"pickle/h1_dbd.pick\")\n",
    "h2_dbd = pd.read_pickle(\"pickle/h2_dbd.pick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "collected-satin",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'CheckoutDate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CheckoutDate'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-b245d9366c19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_reservations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh1_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"2017-08-01\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX1_cxl_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/hotel-revman-system/code/utils.py\u001b[0m in \u001b[0;36msplit_reservations\u001b[0;34m(df_res, as_of_date, features, y_col)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0mas_of_dt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mas_of_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"%Y-%m-%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     test_mask = (df_res[\"ResMadeDate\"] <= as_of_date) & (\n\u001b[0;32m--> 322\u001b[0;31m         \u001b[0mdf_res\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CheckoutDate\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mas_of_date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m     )\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3080\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3082\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3084\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'CheckoutDate'"
     ]
    }
   ],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = split_reservations(h1_res, \"2017-08-01\", features=X1_cxl_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "willing-latest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SIMPLE LR Validation R^2 score was: 0.8300049925112332\n",
      "Test score:  0.2829505741387918\n",
      "\n",
      "RIDGE Validation R^2 score was: 0.3150907949370658\n",
      "\n",
      "LASSO Validation R^2 score was: 0.31497972457165135\n"
     ]
    }
   ],
   "source": [
    "def regularization(X, y):\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=.25, random_state=42)\n",
    "    \n",
    "    # standardize data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train.values)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    # logistic regression\n",
    "    lr = LogisticRegression(max_iter=500)\n",
    "    lr_model = lr.fit(X_train_scaled, y_train)\n",
    "    lr_score = lr_model.score(X_val_scaled, y_val)\n",
    "    \n",
    "    # ridge\n",
    "    ridge = RidgeCV(cv=5)\n",
    "    ridge_model = ridge.fit(X_train_scaled, y_train)\n",
    "    ridge_score = ridge_model.score(X_val_scaled, y_val)\n",
    "    \n",
    "    # lasso\n",
    "    lasso = LassoCV(cv=5)\n",
    "    lasso_model = lasso.fit(X_train_scaled, y_train)\n",
    "    lasso_score = lasso_model.score(X_val_scaled, y_val)\n",
    "    \n",
    "    print('\\nSIMPLE LR Validation R^2 score was:', lr_score)\n",
    "#     print('Feature coefficient results: \\n')\n",
    "    print('Test score: ', lr_model.score(X_test, y_test))\n",
    "#     for feature, coef in zip(X.columns, lr_model.coef_):\n",
    "#         print(feature, ':', f'{coef:.2f}') \n",
    "    \n",
    "    print('\\nRIDGE Validation R^2 score was:', ridge_score)\n",
    "#     print('Feature coefficient results: \\n')\n",
    "#     for feature, coef in zip(X.columns, ridge_model.coef_):\n",
    "#         print(feature, ':', f'{coef:.2f}') \n",
    "        \n",
    "    print('\\nLASSO Validation R^2 score was:', lasso_score)\n",
    "#     print('Feature coefficient results: \\n')\n",
    "#     for feature, coef in zip(X.columns, lasso_model.coef_):\n",
    "#         print(feature, ':', f'{coef:.2f}') \n",
    "    \n",
    "\n",
    "regularization(X1, y1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-vietnam",
   "metadata": {},
   "source": [
    "## XGBoost (Hotel 1): Hyperparameter Tuning with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "serial-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = XGBClassifier(objective='binary:logistic',\n",
    "                          use_label_encoder=False,\n",
    "                          eval_metric='logloss',\n",
    "                          random_state=42,\n",
    "                          max_depth=5\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.08, 0.09, 0.1, 0.11, 0.12],\n",
    "    'n_estimators': [380, 390, 400, 410, 420, 475]\n",
    "}\n",
    "\n",
    "grid_search_1 = GridSearchCV(\n",
    "    estimator = estimator,\n",
    "    param_grid = params,\n",
    "    n_jobs=-1,\n",
    "    verbose=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "original-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "competent-grade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "The best parameters are: \n",
      " {'learning_rate': 0.11, 'n_estimators': 475}\n",
      "CPU times: user 49.1 s, sys: 437 ms, total: 49.5 s\n",
      "Wall time: 4h 8min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_xgb_fit_1 = grid_search_1.fit(X1_train, y1_train)\n",
    "print(\"The best parameters are: \\n\", grid_xgb_fit_1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-victory",
   "metadata": {},
   "source": [
    "## XGBoost (Hotel 2): Hyperparameter Tuning with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "chemical-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = XGBClassifier(objective='binary:logistic',\n",
    "                          use_label_encoder=False,\n",
    "                          eval_metric='logloss',\n",
    "                          random_state=42,\n",
    ")\n",
    "\n",
    "# further tuning params\n",
    "params = {\n",
    "    'learning_rate': [0.08, 0.09, 0.1, 0.11, 0.12],\n",
    "    'n_estimators': [440, 450, 475, 500, 550]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search_2 = GridSearchCV(\n",
    "    estimator = estimator,\n",
    "    param_grid = params,\n",
    "    n_jobs=-1,\n",
    "    verbose=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "excess-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "marked-breakfast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "The best parameters are: \n",
      " {'learning_rate': 0.12, 'n_estimators': 550}\n",
      "CPU times: user 2min 8s, sys: 187 ms, total: 2min 8s\n",
      "Wall time: 5h 5min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_xgb_fit_2 = grid_search_2.fit(X2_train, y2_train)\n",
    "print(\"The best parameters are: \\n\", grid_xgb_fit_2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-florence",
   "metadata": {},
   "source": [
    "### First grid search results\n",
    "\n",
    "**H1 grid search setup**\n",
    "```\n",
    "estimator = XGBClassifier(objective='binary:logistic',\n",
    "                          use_label_encoder=False,\n",
    "                          eval_metric='logloss',\n",
    "                          random_state=42,\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.0001,0.01],\n",
    "    'max_depth': range(2,8,2),\n",
    "    'n_estimators': [200, 300, 400]\n",
    "}\n",
    "\n",
    "grid_search_1 = GridSearchCV(\n",
    "    estimator = estimator,\n",
    "    param_grid = params,\n",
    "    n_jobs=-1,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2,random_state=42)\n",
    "\n",
    "```\n",
    "\n",
    "**And the results**:\n",
    "```\n",
    "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
    "The best parameters are: \n",
    " {'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 400}\n",
    "CPU times: user 53.5 s, sys: 414 ms, total: 53.9 s\n",
    "Wall time: 1h 27min 17s\n",
    "```\n",
    "\n",
    "R^2 score: 0.830629056415377\n",
    "\n",
    "**H2 grid search setup was the same as H1 grid search setup (round 1)**\n",
    "\n",
    "**And the results**:\n",
    "\n",
    "```\n",
    "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
    "The best parameters are: \n",
    " {'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 400}\n",
    "CPU times: user 1min 37s, sys: 262 ms, total: 1min 38s\n",
    "Wall time: 1h 32min 4s\n",
    "```\n",
    "\n",
    "R^2 score: 0.8276818353712341\n",
    "\n",
    "### Second Round\n",
    "\n",
    "H1 setup & results\n",
    "```\n",
    "estimator = XGBClassifier(objective='binary:logistic',\n",
    "                          use_label_encoder=False,\n",
    "                          eval_metric='logloss',\n",
    "                          random_state=42,\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.005, 0.01, 0.05, 0.1],\n",
    "    'max_depth': range(5,6,7),\n",
    "    'n_estimators': [350, 400, 450]\n",
    "}\n",
    "\n",
    "grid_search_1 = GridSearchCV(\n",
    "    estimator = estimator,\n",
    "    param_grid = params,\n",
    "    n_jobs=-1,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2,random_state=42)\n",
    "\n",
    "# ---------RESULTS----------\n",
    "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
    "The best parameters are: \n",
    " {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 400}\n",
    "CPU times: user 40.9 s, sys: 325 ms, total: 41.2 s\n",
    "Wall time: 1h 37min 13s\n",
    "```\n",
    "\n",
    "R^2 score: 0.8514727908137794\n",
    "\n",
    "H2 results (setup the same as H1 round 2):\n",
    "\n",
    "```\n",
    "\n",
    "# SETUP SAME AS H1 ROUND 2\n",
    "\n",
    "# ---------RESULTS----------\n",
    "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
    "The best parameters are: \n",
    " {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 450}\n",
    "CPU times: user 1min 29s, sys: 236 ms, total: 1min 29s\n",
    "Wall time: 1h 41min 45s\n",
    "```\n",
    "R^2 score: 0.84904827933946\n",
    "\n",
    "### Round 3\n",
    "\n",
    "H1 setup different than H2 setup this time.\n",
    "\n",
    "H1 setup:\n",
    "```\n",
    "estimator = XGBClassifier(objective='binary:logistic',\n",
    "                          use_label_encoder=False,\n",
    "                          eval_metric='logloss',\n",
    "                          random_state=42,\n",
    "                          max_depth=5\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.08, 0.09, 0.1, 0.11, 0.12],\n",
    "    'n_estimators': [380, 390, 400, 410, 420, 475]\n",
    "}\n",
    "\n",
    "grid_search_1 = GridSearchCV(\n",
    "    estimator = estimator,\n",
    "    param_grid = params,\n",
    "    n_jobs=-1,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2,random_state=42)\n",
    "\n",
    "# ---------RESULTS----------\n",
    "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
    "The best parameters are: \n",
    " {'learning_rate': 0.11, 'n_estimators': 475}\n",
    "CPU times: user 49.1 s, sys: 437 ms, total: 49.5 s\n",
    "Wall time: 4h 8min 47s\n",
    "```\n",
    "R^2 score: 0.854218671992012\n",
    "\n",
    "And H2 setup:\n",
    "\n",
    "```\n",
    "estimator = XGBClassifier(objective='binary:logistic',\n",
    "                          use_label_encoder=False,\n",
    "                          eval_metric='logloss',\n",
    "                          random_state=42,\n",
    ")\n",
    "\n",
    "# further tuning params\n",
    "params = {\n",
    "    'learning_rate': [0.08, 0.09, 0.1, 0.11, 0.12],\n",
    "    'n_estimators': [440, 450, 475, 500, 550]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search_2 = GridSearchCV(\n",
    "    estimator = estimator,\n",
    "    param_grid = params,\n",
    "    n_jobs=-1,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2,random_state=42)\n",
    "\n",
    "# ---------RESULTS----------\n",
    "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
    "The best parameters are: \n",
    " {'learning_rate': 0.12, 'n_estimators': 550}\n",
    "CPU times: user 2min 8s, sys: 187 ms, total: 2min 8s\n",
    "Wall time: 5h 5min 44s\n",
    "```\n",
    "\n",
    "R^2 score: 0.8564225387621328"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-dairy",
   "metadata": {},
   "source": [
    "## XGB Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "accepted-dating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.854218671992012"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_xgb1_score = grid_xgb_fit_1.score(X1_test, y1_test)\n",
    "grid_xgb1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "prepared-genre",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8564225387621328"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_xgb2_score = grid_xgb_fit_2.score(X2_test, y2_test)\n",
    "grid_xgb2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cloudy-trainer",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'to_pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8b5e0060929d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_xgb_fit_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pickle/h1_grid_result_1.pick\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgrid_xgb_fit_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pickle/h2_grid_result_1.pick\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'to_pickle'"
     ]
    }
   ],
   "source": [
    "grid_xgb_fit_1.to_pickle(\"pickle/h1_grid_result_1.pick\")\n",
    "grid_xgb_fit_2.to_pickle(\"pickle/h2_grid_result_1.pick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-amazon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
