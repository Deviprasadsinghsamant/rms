{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "instructional-variance",
   "metadata": {},
   "source": [
    "# Preparing our Dataset to Model Demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "known-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "from sklearn.preprocessing import OneHotEncoder as ohe\n",
    "\n",
    "from dbds import generate_hotel_dfs\n",
    "from agg import prep_demand_features\n",
    "from agg_utils import stly_cols_agg, ly_cols_agg, drop_cols_agg, stly_pace_cols, ty_pace_cols\n",
    "\n",
    "pd.options.display.max_rows = 150\n",
    "pd.options.display.max_columns = 250\n",
    "pd.options.display.max_colwidth = None\n",
    "\n",
    "DATE_FMT = \"%Y-%m-%d\"\n",
    "h1_capacity = 187\n",
    "h2_capacity = 226\n",
    "AOD = \"2017-08-01\"\n",
    "AOD_dt = pd.to_datetime(AOD)\n",
    "\n",
    "h1_res = pd.read_pickle(\"pickle/h1_res.pick\")\n",
    "h2_res = pd.read_pickle(\"pickle/h2_res.pick\")\n",
    "h1_dbd = pd.read_pickle(\"pickle/h1_dbd.pick\")\n",
    "h2_dbd = pd.read_pickle(\"pickle/h2_dbd.pick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "concerned-wrist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hotel dataframes generated successfully!\n",
      "Hotel capacity: 187 rooms\n",
      "Hotel data date range: 2015-07-01 to 2017-08-31\n",
      "Hotel dataframes generated successfully!\n",
      "Hotel capacity: 226 rooms\n",
      "Hotel data date range: 2015-07-01 to 2017-08-31\n"
     ]
    }
   ],
   "source": [
    "h1_res, h1_dbd = generate_hotel_dfs(\"../data/H1.csv\", capacity=h1_capacity)\n",
    "h2_res, h2_dbd = generate_hotel_dfs(\"../data/H2.csv\", capacity=h2_capacity)\n",
    "\n",
    "h1_res.to_pickle(\"pickle/h1_res.pick\")\n",
    "h1_dbd.to_pickle(\"pickle/h1_dbd.pick\")\n",
    "h2_res.to_pickle(\"pickle/h2_res.pick\")\n",
    "h2_dbd.to_pickle(\"pickle/h2_dbd.pick\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-poultry",
   "metadata": {},
   "source": [
    "## Combine Files Generated by save_sims.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accredited-assets",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(m)\n\u001b[32m     26\u001b[39m h1_files.sort()\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28mlen\u001b[39m(h1_files), \u001b[43mh1_files\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m, h1_files[-\u001b[32m1\u001b[39m] \u001b[38;5;66;03m# note STLY date of 8/1/17 == 8/2/16 (matching weekday)\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# generate list of relevant files\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "hotel_num = 1\n",
    "h = 'h' + str(hotel_num)\n",
    "SIM_AOD = pd.to_datetime(dt.date(2017, 8, 1), format=DATE_FMT)\n",
    "sim_start = SIM_AOD - pd.DateOffset(365*2) # need > 364 days of actuals for each date, the rest future-looking\n",
    "\n",
    "# FOLDER = \"./sims2/\"\n",
    "# Get the directory of the current script\n",
    "# IMPORTANT: Ensure your Jupyter Notebook or interactive session\n",
    "# is started from the 'rms' directory (e.g., ~/Desktop/rms/rms/)\n",
    "current_working_dir = os.getcwd()\n",
    "\n",
    "# Now define paths relative to this current working directory\n",
    "# Assuming 'code' and 'sims2' are direct subdirectories of the current working directory\n",
    "code_dir = os.path.join(current_working_dir, \"code\")\n",
    "FOLDER = os.path.join(current_working_dir, \"sims2\", \"\") # Path to the sims2 folder\n",
    "\n",
    "# You'll also need to define pickle_dir if you're loading pickle files in this same notebook:\n",
    "pickle_dir = os.path.join(code_dir, \"pickle\")\n",
    "lam_include = lambda x: x[:2] == h and pd.to_datetime(x[7:17]) >= sim_start\n",
    "h1_files = [f for f in os.listdir(FOLDER) if lam_include(f)]\n",
    "m =len(h1_files)\n",
    "print(m)\n",
    "h1_files.sort()\n",
    "len(h1_files), h1_files[0], h1_files[-1] # note STLY date of 8/1/17 == 8/2/16 (matching weekday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advance-output",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_sim = pd.DataFrame()\n",
    "df_list = [pd.read_pickle(FOLDER + otb_data) for otb_data in h1_files]\n",
    "df_sim = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "df_sim.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bronze-maple",
   "metadata": {},
   "source": [
    "## Adding calculated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e15878",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-professor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add AsOfDate\n",
    "\n",
    "def apply_aod(row):\n",
    "    stay_date = row[\"Date\"]\n",
    "    stly_stay_date = pd.to_datetime(row[\"STLY_Date\"])\n",
    "    n_days_b4 = int(row[\"DaysUntilArrival\"])\n",
    "    as_of_date = pd.to_datetime(\n",
    "        stay_date - pd.DateOffset(n_days_b4), format=DATE_FMT\n",
    "    )\n",
    "    stly_as_of_date = pd.to_datetime(\n",
    "        stly_stay_date - pd.DateOffset(n_days_b4), format=DATE_FMT\n",
    "    )\n",
    "    return as_of_date, stly_as_of_date\n",
    "\n",
    "df_sim[[\"AsOfDate\",\"STLY_AsOfDate\"]] = df_sim[[\"Date\", \"STLY_Date\", \"DaysUntilArrival\"]].apply(apply_aod, axis=1, result_type='expand')\n",
    "df_sim.rename(columns={\"Date\": \"StayDate\", \"STLY_Date\": \"STLY_StayDate\"}, inplace=True)\n",
    "\n",
    "df_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-oracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim.shape\n",
    "df_sim[\"AsOfDate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "natural-individual",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add remaining supply ('RemSupply')\n",
    "capacity = 187\n",
    "df_sim[\"RemSupply\"] = (\n",
    "    capacity - df_sim.RoomsOTB.astype(int) + df_sim.CxlForecast.astype(int)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-shame",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add one-hot-encoded DOW ('Day of Week') columns\n",
    "\n",
    "ohe_dow = pd.get_dummies(df_sim.DOW, drop_first=True)\n",
    "dow_ohe_cols = list(ohe_dow.columns)\n",
    "df_sim[dow_ohe_cols] = ohe_dow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-mistress",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accurate-welding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add NONTRN cols\n",
    "\n",
    "df_sim[\"NONTRN_RoomsOTB\"] = (\n",
    "    df_sim.RoomsOTB - df_sim.TRN_RoomsOTB\n",
    ")\n",
    "df_sim[\"NONTRN_RevOTB\"] = df_sim.RevOTB - df_sim.TRN_RevOTB\n",
    "df_sim[\"NONTRN_ADR_OTB\"] = round(df_sim[\"NONTRN_RevOTB\"] / df_sim[\"NONTRN_RoomsOTB\"], 2)\n",
    "df_sim[\"NONTRN_CxlForecast\"] = df_sim.CxlForecast - df_sim.TRN_CxlForecast\n",
    "\n",
    "# df_sim[\"LYA_NONTRN_RoomsOTB\"] = (\n",
    "#     df_sim.LYA_TRNP_RoomsOTB + df_sim.LYA_GRP_RoomsOTB + df_sim.LYA_CNT_RoomsOTB\n",
    "# )\n",
    "# df_sim[\"LYA_NONTRN_RevOTB\"] = df_sim.LYA_TRNP_RevOTB + df_sim.LYA_GRP_RevOTB + df_sim.LYA_CNT_RevOTB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specified-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raising-combining",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ly_cols_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-victorian",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple(np.zeros(7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-appeal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add last-year actual columns (\"LYA_\")\n",
    "\n",
    "def apply_ly_cols(row):\n",
    "    try:\n",
    "        stly_date = pd.to_datetime(row[\"STLY_StayDate\"])\n",
    "        cutoff_date = pd.to_datetime('2015-08-01')\n",
    "        if stly_date < cutoff_date:\n",
    "            return tuple(np.zeros(len(ly_cols_agg)))\n",
    "        stly_date_str = stly_date.strftime(DATE_FMT)\n",
    "        df_lya = list(h1_dbd.loc[stly_date_str, ly_cols_agg])\n",
    "        return tuple(df_lya)\n",
    "    except:\n",
    "        return tuple(np.zeros(len(ly_cols_agg)))\n",
    "\n",
    "ly_new_cols = [\"LYA_\" + col for col in ly_cols_agg]\n",
    "df_sim[ly_new_cols] = df_sim[[\"STLY_StayDate\"]].apply(apply_ly_cols, axis=1, result_type=\"expand\")\n",
    "\n",
    "df_sim.fillna(0, inplace=True)\n",
    "\n",
    "df_sim.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-newcastle",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_cols = ['RoomsSold', \"ADR\", \"RoomRev\", \"NumCancels\"]\n",
    "def apply_ty_actuals(row):\n",
    "    date = row[\"StayDate\"]\n",
    "    date_str = dt.datetime.strftime(date, format=DATE_FMT)\n",
    "    results = list(h1_dbd.loc[date_str, actual_cols])\n",
    "    return tuple(results)\n",
    "\n",
    "new_actual_cols = [\"ACTUAL_\" + col for col in actual_cols]\n",
    "df_sim[new_actual_cols] = df_sim[[\"StayDate\"]].apply(apply_ty_actuals, axis=1, result_type=\"expand\")\n",
    "\n",
    "df_sim.fillna(0, inplace=True)\n",
    "\n",
    "df_sim.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65aad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim[\"AsOfDate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disciplinary-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_sim.StayDate == '2017-08-09'\n",
    "df_sim[mask][[\"ACTUAL_RoomsSold\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-first",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_dbd.loc[\"2017-08-09\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-orleans",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_dbd.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-flower",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim.columns\n",
    "# df_sim[\"AsOfDate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4491e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim[\"NONTRN_ADR_OTB\"] = round(df_sim[\"NONTRN_RevOTB\"] / df_sim[\"NONTRN_RoomsOTB\"], 2)\n",
    "# df_sim[\"TM30_NONTRN_RevOTB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302f35c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim[\"AsOfDate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ADR for all segments first\n",
    "\n",
    "df_sim[\"ADR_OTB\"] = round(df_sim[\"RevOTB\"] / df_sim[\"RoomsOTB\"], 2)\n",
    "df_sim[\"TRN_ADR_OTB\"] = round(df_sim[\"TRN_RevOTB\"] / df_sim[\"TRN_RoomsOTB\"], 2)\n",
    "df_sim[\"NONTRN_ADR_OTB\"] = round(df_sim[\"NONTRN_RevOTB\"] / df_sim[\"NONTRN_RoomsOTB\"], 2)\n",
    "\n",
    "# get recent pickup (tminus) columns\n",
    "tms = [\"TM30_\", \"TM15_\", \"TM05_\"]\n",
    "segs = [\"\", \"TRN_\"] # \"\" for total hotel\n",
    "\n",
    "for tm in tms:\n",
    "    # Calculate ADR for tminus windows first\n",
    "    df_sim[tm + \"ADR_OTB\"] = round(df_sim[tm + \"RevOTB\"] / df_sim[tm + \"RoomsOTB\"], 2)\n",
    "    df_sim[tm + \"TRN_ADR_OTB\"] = round(df_sim[tm + \"TRN_RevOTB\"] / df_sim[tm + \"TRN_RoomsOTB\"], 2)\n",
    "\n",
    "    # Calculate NONTRN ADR for tminus windows\n",
    "    # df_sim[tm + \"NONTRN_ADR_OTB\"] = round(df_sim[tm + \"NONTRN_RevOTB\"] / df_sim[tm + \"NONTRN_RoomsOTB\"], 2)\n",
    "    \n",
    "    for seg in segs:\n",
    "        # Calculate pickup stats\n",
    "        df_sim[tm + seg + \"RoomsPickup\"] = round(\n",
    "            df_sim[seg + \"RoomsOTB\"] - df_sim[tm + seg + \"RoomsOTB\"], 2\n",
    "        )\n",
    "        df_sim[tm + seg + \"RevPickup\"] = round(\n",
    "            df_sim[seg + \"RevOTB\"] - df_sim[tm + seg + \"RevOTB\"], 2\n",
    "        )\n",
    "        df_sim[tm + seg + \"ADR_Pickup\"] = round(\n",
    "            df_sim[seg + \"ADR_OTB\"] - df_sim[tm + seg + \"ADR_OTB\"], 2\n",
    "        )\n",
    "    \n",
    "    # Calculate NONTRN pickup stats\n",
    "    tm_nontrn_rooms_otb = tm + \"NONTRN_RoomsOTB\"\n",
    "    nontrn_rooms_otb = \"NONTRN_RoomsOTB\"\n",
    "    tm_nontrn_rev_otb = tm + \"NONTRN_RevOTB\"\n",
    "    nontrn_rev_otb = \"NONTRN_RevOTB\"\n",
    "    tm_nontrn_adr_otb = tm + \"NONTRN_ADR_OTB\"\n",
    "    nontrn_adr_otb = \"NONTRN_ADR_OTB\"\n",
    "\n",
    "    if nontrn_rooms_otb in df_sim.columns:\n",
    "        if tm_nontrn_rooms_otb not in df_sim.columns:\n",
    "            df_sim[tm_nontrn_rooms_otb] = 0  # Fill missing column with 0\n",
    "        df_sim[tm + \"NONTRN_RoomsPickup\"] = (\n",
    "            df_sim[nontrn_rooms_otb] - df_sim[tm_nontrn_rooms_otb]\n",
    "        )\n",
    "    if nontrn_rev_otb in df_sim.columns:\n",
    "        if tm_nontrn_rev_otb not in df_sim.columns:\n",
    "            df_sim[tm_nontrn_rev_otb] = 0  # Fill missing column with 0\n",
    "        df_sim[tm + \"NONTRN_RevPickup\"] = (\n",
    "            df_sim[nontrn_rev_otb] - df_sim[tm_nontrn_rev_otb]\n",
    "        )\n",
    "    if nontrn_adr_otb in df_sim.columns:\n",
    "        if tm_nontrn_adr_otb not in df_sim.columns:\n",
    "            df_sim[tm_nontrn_adr_otb] = 0  # Fill missing column with 0\n",
    "        df_sim[tm + \"NONTRN_ADR_Pickup\"] = (\n",
    "            df_sim[nontrn_adr_otb] - df_sim[tm_nontrn_adr_otb]\n",
    "        )\n",
    "\n",
    "df_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cleared-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim.shape\n",
    "df_sim[\"AsOfDate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9829483b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jewish-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add gap to LYA columns (by segment)\n",
    "# must be done AFTER NONTRN cols added\n",
    "df_sim[\"RoomsGapToLYA\"] = df_sim.LYA_RoomsSold - df_sim.RoomsOTB\n",
    "df_sim[\"RevGapToLYA\"] = df_sim.LYA_RoomRev - df_sim.RevOTB\n",
    "df_sim[\"ADR_GapToLYA\"] = df_sim.LYA_ADR - df_sim.ADR_OTB\n",
    "\n",
    "df_sim[\"TRN_RoomsGapToLYA\"] = df_sim.LYA_TRN_RoomsSold - df_sim.TRN_RoomsOTB\n",
    "df_sim[\"TRN_RevGapToLYA\"] = df_sim.LYA_TRN_RoomRev - df_sim.TRN_RevOTB\n",
    "df_sim[\"TRN_ADR_GapToLYA\"] = df_sim.LYA_TRN_ADR - df_sim.TRN_ADR_OTB\n",
    "\n",
    "df_sim[\"NONTRN_RoomsGapToLYA\"] = df_sim[\"RoomsGapToLYA\"] - df_sim[\"TRN_RoomsGapToLYA\"]\n",
    "df_sim[\"NONTRN_RevGapToLYA\"] = df_sim[\"RevGapToLYA\"] - df_sim[\"TRN_RevGapToLYA\"]\n",
    "df_sim[\"NONTRN_ADR_GapToLYA\"] = df_sim[\"ADR_GapToLYA\"] - df_sim[\"TRN_ADR_GapToLYA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-quebec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "devoted-preference",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "found-russian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all non-gap, non-pickup actual/tminus columns\n",
    "# I will want to move this down in our script to combine with removing stly cols (we only want pace)\n",
    "# removing them here just to make it cleaner\n",
    "\n",
    "df_sim.drop(columns=drop_cols_agg, inplace=True, errors='ignore')\n",
    "df_sim.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "absolute-banks",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim.sample(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sim.loc[\"2016-04-24\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-limitation",
   "metadata": {},
   "source": [
    "# EW- NEXT STEPS (THU 5PM)\n",
    "\n",
    "1. drop unneeded, post-processed TM_nn columns in blank cell above (create list in agg_utils.py)\n",
    "2. pull stly cols via merge below\n",
    "3. calculate pace\n",
    "4. drop unneeded, post-processed stly cols\n",
    "5. add all of the steps in this notebook to agg.py\n",
    "6. pull features from list at top of this NB\n",
    "7. train/test split\n",
    "8. linear regression (predict RoomsSold)\n",
    "9. randomForest (predict RoomsSold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "southwest-mapping",
   "metadata": {},
   "source": [
    "**Time to pull STLY columns. I will accomplish this by merging df_sim on top of itself and pulling the below columns into the next year's row with the `'STLY_'` prefix.***\n",
    "\n",
    "But before we do that, let's make sure we add in the ADR columns.\n",
    "\n",
    "NEVERMIND - THIS STEP NEEDS TO COME LAST ONCE WE HAVE ALL OF THE OTHER COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-translator",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccda4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naval-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull STLY columns with self-merge to STLY date\n",
    "\n",
    "# first, we need to create unique ID col (id) for each as-of-date/stay-date combo\n",
    "# then, we manipulate strings to add a stly_id column that we can use as right key for our merge\n",
    "\n",
    "df_sim_ids = df_sim.AsOfDate.astype(str) + ' - ' + df_sim.StayDate.astype(str)\n",
    "df_sim.insert(0, \"id\", df_sim_ids)\n",
    "\n",
    "df_sim_stly_ids = df_sim.STLY_AsOfDate.astype(str) + ' - ' + df_sim.STLY_StayDate.astype(str)\n",
    "df_sim.insert(1, \"stly_id\", df_sim_stly_ids)\n",
    "df_sim.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-level",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim[\"DayOfWeek\"] df_sim.StayDate.map(lambda x: dt.datetime.strftime(x, format=\"%a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-andrews",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crucial-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# self-join df_sim to pull stly stats using the above keys\n",
    "\n",
    "df_sim = df_sim.merge(df_sim[stly_cols_agg], left_on='stly_id', right_on='id', suffixes=(None, \"_STLY\"))\n",
    "df_sim.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spiritual-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim[['id', 'stly_id', 'AsOfDate', 'StayDate', 'AsOfDate_STLY', 'StayDate_STLY', 'RoomsOTB_STLY', 'RevOTB_STLY']]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sim[df_sim.AsOfDate_STLY.isna()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sim.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c in df_sim.columns if c[-5:] == '_STLY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitive-display",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finished-zambia",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_stly = pd.read_pickle(\"./sims/pickle/h1_sim_2016-08-02.pick\")\n",
    "df_test_stly.loc[\"2016-08-06\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (venv)",
   "language": "python",
   "name": "jupyterenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
