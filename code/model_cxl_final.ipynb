{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "moral-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, f1_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from utils import split_reservations\n",
    "from features import X1_cxl_cols, X2_cxl_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "polish-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 60\n",
    "pd.options.display.max_columns = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "novel-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_res = pd.read_pickle(\"pickle/h1_res.pick\")\n",
    "h2_res = pd.read_pickle(\"pickle/h2_res.pick\")\n",
    "h1_dbd = pd.read_pickle(\"pickle/h1_dbd.pick\")\n",
    "h2_dbd = pd.read_pickle(\"pickle/h2_dbd.pick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "finished-postcard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample size: 38295 \n",
      " Testing Sample Size: 1765\n"
     ]
    }
   ],
   "source": [
    "X_1 = split_reservations(h1_res, as_of_date=\"2017-08-01\", features=X1_cxl_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "massive-pattern",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sample size: 79330 \n",
      " Testing Sample Size: 0\n"
     ]
    }
   ],
   "source": [
    "X_2 = split_reservations(h2_res, as_of_date=\"2027-08-01\", features=X2_cxl_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-portrait",
   "metadata": {},
   "source": [
    "## H1 Final XGBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-control",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_1 = XGBClassifier(objective='binary:logistic',\n",
    "                      use_label_encoder=False,\n",
    "                      eval_metric='logloss',\n",
    "                      random_state=42,\n",
    "                      n_jobs=-1,\n",
    "                      learning_rate=0.11,\n",
    "                      max_depth=5,\n",
    "                      n_estimators=475\n",
    "                          \n",
    ")\n",
    "\n",
    "xgb_model_1 = xgb_1.fit(X1_train, y1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-shopper",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_preds = xgb_model_1.predict(X1_test)\n",
    "f1_score(y1_test, h1_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1[\"WillCancel\"] = h1_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-florence",
   "metadata": {},
   "source": [
    "### First grid search results\n",
    "\n",
    "**H1 grid search setup**\n",
    "```\n",
    "estimator = XGBClassifier(objective='binary:logistic',\n",
    "                          use_label_encoder=False,\n",
    "                          eval_metric='logloss',\n",
    "                          random_state=42,\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.0001,0.01],\n",
    "    'max_depth': range(2,8,2),\n",
    "    'n_estimators': [200, 300, 400]\n",
    "}\n",
    "\n",
    "grid_search_1 = GridSearchCV(\n",
    "    estimator = estimator,\n",
    "    param_grid = params,\n",
    "    n_jobs=-1,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2,random_state=42)\n",
    "\n",
    "```\n",
    "\n",
    "**And the results**:\n",
    "```\n",
    "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
    "The best parameters are: \n",
    " {'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 400}\n",
    "CPU times: user 53.5 s, sys: 414 ms, total: 53.9 s\n",
    "Wall time: 1h 27min 17s\n",
    "```\n",
    "\n",
    "R^2 score: 0.830629056415377\n",
    "\n",
    "**H2 grid search setup was the same as H1 grid search setup (round 1)**\n",
    "\n",
    "**And the results**:\n",
    "\n",
    "```\n",
    "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
    "The best parameters are: \n",
    " {'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 400}\n",
    "CPU times: user 1min 37s, sys: 262 ms, total: 1min 38s\n",
    "Wall time: 1h 32min 4s\n",
    "```\n",
    "\n",
    "R^2 score: 0.8276818353712341\n",
    "\n",
    "### Second Round\n",
    "\n",
    "H1 setup & results\n",
    "```\n",
    "estimator = XGBClassifier(objective='binary:logistic',\n",
    "                          use_label_encoder=False,\n",
    "                          eval_metric='logloss',\n",
    "                          random_state=42,\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.005, 0.01, 0.05, 0.1],\n",
    "    'max_depth': range(5,6,7),\n",
    "    'n_estimators': [350, 400, 450]\n",
    "}\n",
    "\n",
    "grid_search_1 = GridSearchCV(\n",
    "    estimator = estimator,\n",
    "    param_grid = params,\n",
    "    n_jobs=-1,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2,random_state=42)\n",
    "\n",
    "# ---------RESULTS----------\n",
    "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
    "The best parameters are: \n",
    " {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 400}\n",
    "CPU times: user 40.9 s, sys: 325 ms, total: 41.2 s\n",
    "Wall time: 1h 37min 13s\n",
    "```\n",
    "\n",
    "R^2 score: 0.8514727908137794\n",
    "\n",
    "H2 results (setup the same as H1 round 2):\n",
    "\n",
    "```\n",
    "\n",
    "# SETUP SAME AS H1 ROUND 2\n",
    "\n",
    "# ---------RESULTS----------\n",
    "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
    "The best parameters are: \n",
    " {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 450}\n",
    "CPU times: user 1min 29s, sys: 236 ms, total: 1min 29s\n",
    "Wall time: 1h 41min 45s\n",
    "```\n",
    "R^2 score: 0.84904827933946\n",
    "\n",
    "### Round 3\n",
    "\n",
    "H1 setup different than H2 setup this time.\n",
    "\n",
    "H1 setup:\n",
    "```\n",
    "estimator = XGBClassifier(objective='binary:logistic',\n",
    "                          use_label_encoder=False,\n",
    "                          eval_metric='logloss',\n",
    "                          random_state=42,\n",
    "                          max_depth=5\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.08, 0.09, 0.1, 0.11, 0.12],\n",
    "    'n_estimators': [380, 390, 400, 410, 420, 475]\n",
    "}\n",
    "\n",
    "grid_search_1 = GridSearchCV(\n",
    "    estimator = estimator,\n",
    "    param_grid = params,\n",
    "    n_jobs=-1,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2,random_state=42)\n",
    "\n",
    "# ---------RESULTS----------\n",
    "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
    "The best parameters are: \n",
    " {'learning_rate': 0.11, 'n_estimators': 475}\n",
    "CPU times: user 49.1 s, sys: 437 ms, total: 49.5 s\n",
    "Wall time: 4h 8min 47s\n",
    "```\n",
    "R^2 score: 0.854218671992012\n",
    "\n",
    "And H2 setup:\n",
    "\n",
    "```\n",
    "estimator = XGBClassifier(objective='binary:logistic',\n",
    "                          use_label_encoder=False,\n",
    "                          eval_metric='logloss',\n",
    "                          random_state=42,\n",
    ")\n",
    "\n",
    "# further tuning params\n",
    "params = {\n",
    "    'learning_rate': [0.08, 0.09, 0.1, 0.11, 0.12],\n",
    "    'n_estimators': [440, 450, 475, 500, 550]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search_2 = GridSearchCV(\n",
    "    estimator = estimator,\n",
    "    param_grid = params,\n",
    "    n_jobs=-1,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2,random_state=42)\n",
    "\n",
    "# ---------RESULTS----------\n",
    "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
    "The best parameters are: \n",
    " {'learning_rate': 0.12, 'n_estimators': 550}\n",
    "CPU times: user 2min 8s, sys: 187 ms, total: 2min 8s\n",
    "Wall time: 5h 5min 44s\n",
    "```\n",
    "\n",
    "R^2 score: 0.8564225387621328"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-amazon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
