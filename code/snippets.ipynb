{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "seven-intent",
   "metadata": {},
   "source": [
    "# Snippets\n",
    "\n",
    "## This file houses important bits and pieces of the code used (or not) in my scripts for this project\n",
    "\n",
    "Contains solutions to various problems I encountered, for future reference.\n",
    "\n",
    "### This notebook is NOT intended to be run. This is just a scratchpad (working code only)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "binding-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "pd.options.display.max_rows = 60\n",
    "pd.options.display.max_columns = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "gentle-producer",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'pickle/h1_sim.pick'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m h1_dbd \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpickle/h1_dbd.pick\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m h2_dbd \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpickle/h2_dbd.pick\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m h1_sim \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_pickle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpickle/h1_sim.pick\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m h2_sim \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_pickle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpickle/h2_sim.pick\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Quotus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\pickle.py:185\u001b[0m, in \u001b[0;36mread_pickle\u001b[1;34m(filepath_or_buffer, compression, storage_options)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03mLoad pickled pandas object (or any object) from file.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m4    4    9\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    184\u001b[0m excs_to_catch \u001b[38;5;241m=\u001b[39m (\u001b[38;5;167;01mAttributeError\u001b[39;00m, \u001b[38;5;167;01mImportError\u001b[39;00m, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m)\n\u001b[1;32m--> 185\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;66;03m# 1) try standard library Pickle\u001b[39;00m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;66;03m# 2) try pickle_compat (older pandas version) to handle subclass changes\u001b[39;00m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# 3) try pickle_compat with latin-1 encoding upon a UnicodeDecodeError\u001b[39;00m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    197\u001b[0m         \u001b[38;5;66;03m# TypeError for Cython complaints about object.__new__ vs Tick.__new__\u001b[39;00m\n\u001b[0;32m    198\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Quotus\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pickle/h1_sim.pick'"
     ]
    }
   ],
   "source": [
    "DATE_FMT = \"%Y-%m-%d\"\n",
    "AOD = '2017-08-01'\n",
    "AOD_str = pd.to_datetime(AOD, format=DATE_FMT)\n",
    "\n",
    "h1_res = pd.read_pickle(\"pickle/h1_res.pick\")\n",
    "h2_res = pd.read_pickle(\"pickle/h2_res.pick\")\n",
    "h1_dbd = pd.read_pickle(\"pickle/h1_dbd.pick\")\n",
    "h2_dbd = pd.read_pickle(\"pickle/h2_dbd.pick\")\n",
    "h1_sim = pd.read_pickle(\"pickle/h1_sim.pick\")\n",
    "h2_sim = pd.read_pickle(\"pickle/h2_sim.pick\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "everyday-crossing",
   "metadata": {},
   "source": [
    "## Get the last day of the week for a series of dates (fully vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vietnamese-pioneer",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_sim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_sim[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWeekEndDate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf_sim\u001b[49m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[0;32m      2\u001b[0m         \u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m pd\u001b[38;5;241m.\u001b[39mDateOffset(weekday\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m6\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      3\u001b[0m     )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_sim' is not defined"
     ]
    }
   ],
   "source": [
    "df_sim[\"WeekEndDate\"] = df_sim.apply(\n",
    "        lambda x: x[\"Date\"] + pd.DateOffset(weekday=6), axis=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pressing-columbus",
   "metadata": {},
   "source": [
    "## Estimate selling prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-terminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rate_mapper(night):\n",
    "    mask = (\n",
    "        (df_res.ArrivalDate <= night)\n",
    "        & (df_res.CheckoutDate > night)\n",
    "        & (df_res.CustomerType == \"Transient\")\n",
    "    )\n",
    "    df_pricing_res = df_res[mask].copy()\n",
    "    price = round(df_pricing_res[mask].ADR.mean(), 2)\n",
    "    return price\n",
    "\n",
    "df_sim[\"SellingPrice\"] = df_sim[\"Date\"].map(rate_mapper)\n",
    "\n",
    "return df_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-crystal",
   "metadata": {},
   "source": [
    "## Estimate selling price (as of a given date) using only actualized reservations (WD/WE Pricing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_pricing(df_sim):\n",
    "    \"\"\"\n",
    "    Adds 'SellingPrice' column to df_sim.\n",
    "\n",
    "    Contains the average rate for all booked reservations during a given week (WD/WE).\n",
    "    This gives us an indication of what the hotel's online selling prices.\n",
    "    \"\"\"\n",
    "    # get average WD/WE pricing for each week\n",
    "    df_sim.index = pd.to_datetime(df_sim.index, format=\"%Y-%m-%d\")\n",
    "    df_pricing = (\n",
    "        df_sim[[\"Trn_RoomsOTB\", \"Trn_RevOTB\", \"WD\"]]\n",
    "        .groupby([pd.Grouper(freq=\"1W\"), \"WD\"])\n",
    "        .agg(\"sum\")\n",
    "    )\n",
    "    df_pricing = df_pricing.reset_index().rename(columns={\"level_0\": \"Date\"})\n",
    "    df_pricing[\"Date\"] = pd.to_datetime(df_pricing.Date, format=\"%Y-%m-%d\")\n",
    "    df_pricing[\"Trn_ADR_OTB\"] = round(\n",
    "        df_pricing.Trn_RevOTB / df_pricing.Trn_RoomsOTB, 2\n",
    "    )\n",
    "    df_pricing.index = df_pricing.Date\n",
    "\n",
    "\n",
    "    df_sim[\"Date\"] = df_sim.index\n",
    "    # have to do it this way to prevent performance warning (non-vectorized operation)\n",
    "    df_sim[\"WeekEndDate\"] = df_sim.apply(\n",
    "        lambda x: x[\"Date\"] + pd.DateOffset(weekday=6), axis=1\n",
    "    )\n",
    "\n",
    "    # apply the weekly WD/WE prices to the original df_sim\n",
    "    def apply_rates(row):\n",
    "        wd = row[\"WD\"] == 1\n",
    "        date = datetime.datetime.strftime(row.name, format=\"%Y-%m-%d\")\n",
    "        week_end = datetime.datetime.strftime(row.WeekEndDate, format=\"%Y-%m-%d\")\n",
    "        mask = df_pricing.WD == wd\n",
    "        price = df_pricing[mask].loc[week_end, \"Trn_ADR_OTB\"]\n",
    "        return price\n",
    "\n",
    "    df_sim[\"SellingPrice\"] = df_sim.apply(apply_rates, axis=1)\n",
    "\n",
    "    return df_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c4ef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-enforcement",
   "metadata": {},
   "source": [
    "## Filter for future reservations as of a given date\n",
    "\n",
    "This cell runs if you ran the top two Python cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "as_of_date=\"2017-08-16\"\n",
    "h1_res['ReservationStatusDate'] = pd.to_datetime(h1_res.ReservationStatusDate)\n",
    "otb_mask = (\n",
    "    (h1_res.ResMadeDate <= as_of_date)  # reservations made before AOD\n",
    "    & (h1_res.CheckoutDate > as_of_date)  # checking out after AOD\n",
    ") & (\n",
    "    (h1_res.IsCanceled == 0)\n",
    "    | (\n",
    "        (  # only include cxls that have not been canceled yet\n",
    "            (h1_res.IsCanceled == 1) & (h1_res.ReservationStatusDate >= as_of_date)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "h1_res_aod = h1_res[otb_mask][['IsCanceled', 'ArrivalDate', 'CheckoutDate', 'ResMadeDate', 'ReservationStatus', 'ReservationStatusDate']]\n",
    "h1_res_aod.sort_values('ReservationStatusDate', ascending=False, inplace=True)\n",
    "h1_res_aod.sample(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-mobile",
   "metadata": {},
   "source": [
    "## Generate a list of dates from d1 to d2 (inclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-content",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "d1 = datetime.date(2020, 1, 1)\n",
    "d2 = datetime.date(2020, 4, 1)\n",
    "all_dates = [datetime.datetime.strftime(d1 + datetime.timedelta(days=x), format=\"%Y-%m-%d\") for x in range((d2-d1).days + 1)]\n",
    "all_dates[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sexual-baptist",
   "metadata": {},
   "source": [
    "## Add CheckoutDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkout_lam = lambda row: row[\"ArrivalDate\"] + pd.DateOffset(row[\"LOS\"])\n",
    "df_res[\"CheckoutDate\"] = df_res.apply(checkout_lam, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outer-glance",
   "metadata": {},
   "source": [
    "## Get Same-Time-Last Year Date (same weekday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-annex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how we can get the STLY of a given date (today, for example)\n",
    "NOW = datetime.now()\n",
    "STLY_weekday = NOW+relativedelta(years=-1, weekday=2)\n",
    "print(STLY_weekday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and in pandas\n",
    "ty_dates = pd.to_datetime(h1_dbd.index)\n",
    "stly_lambda = lambda x: x + relativedelta(years=-1, weekday=x.weekday())\n",
    "stly = ty_dates.map(stly_lambda)\n",
    "h1_dbd[\"STLY_Date\"] = pd.to_datetime(stly, format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-passenger",
   "metadata": {},
   "source": [
    "## One-Hot encode a variable in a way that can be repeated with different values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operating-position",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-encode Country\n",
    "top_ten_countries = list(\n",
    "    df_res.Country.value_counts().sort_values(ascending=False).head(10).index\n",
    ")\n",
    "\n",
    "for country in top_ten_countries:\n",
    "    df_res[\"FROM_\" + country] = df_res.Country == country\n",
    "\n",
    "df_res[\"FROM_other\"] = ~df_res.Country.isin(top_ten_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controversial-minimum",
   "metadata": {},
   "source": [
    "## Converting Reservations DataFrame --> Hotel DayByDays\n",
    "\n",
    "Known inefficiency: I am going back 60 nights for each arrival date, when that's probably not necessary, per below histograms. However, I am going back as far as the maximum LOS in the dataset, so if I don't go back that far, I will miss it. \n",
    "\n",
    "A potential solution would be to create a sparse matrix containing reservation_ids and a list of their indices in a vectorized representation of reservation nights. Like so:\n",
    "\n",
    "```\n",
    "# dense matrix\n",
    "\n",
    "[['res_id', '2020-01-01', '2020-01-02', '2020-01-03', '2020-01-04', '2020-01-05', '2020-01-06'],\n",
    " ['000000', 1, 1, 0, 0, 0, 0],\n",
    " ['000001', 0, 0, 1, 1, 1, 1],\n",
    " ['000002', 0, 1, 0, 0, 0, 0]]\n",
    "\n",
    "# sparse matrix\n",
    "[('000000', '2020-01-01', '2020-01-02'),\n",
    " ('000001', '2020-01-03', '2020-01-04', '2020-01-05', '2020-01-06'),\n",
    " ('000002', '2020-01-02')]\n",
    "```\n",
    "\n",
    "I will add this to my list for things to do after the presentation, but for now, need to push onwards!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aerial-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "h1_res = pd.read_pickle(\"pickle/h1_res.pick\")\n",
    "\n",
    "plt.hist(h1_res.LOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tutorial-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2_res = pd.read_pickle(\"pickle/h2_res.pick\")\n",
    "\n",
    "plt.hist(h2_res.LOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accompanied-anderson",
   "metadata": {},
   "outputs": [],
   "source": [
    "def res_to_dbd(df_res):\n",
    "    \"\"\"\n",
    "    Takes a dataFrame (with parsed dates and LOS column) containing a hotel's reservations and\n",
    "    returns a DataFrame containing nightly hotel room sales.\n",
    "\n",
    "    Our data is made up of reservations containing 'Arrival Date' and 'Length of Stay'.\n",
    "    This function is used to determine how many rooms were sold on a given night, accounting for\n",
    "    guests that arrived previously and are staying multiple nights.\n",
    "    \"\"\"\n",
    "    mask = df_res[\"IsCanceled\"] == 0\n",
    "    df_dates = df_res[mask]\n",
    "\n",
    "    date = datetime.date(2015, 7, 1)\n",
    "    end_date = datetime.date(2017, 8, 31)\n",
    "    delta = datetime.timedelta(days=1)\n",
    "    max_los = int(df_dates[\"LOS\"].max())\n",
    "\n",
    "    nightly_stats = {}\n",
    "\n",
    "    while date <= end_date:\n",
    "\n",
    "        date_string = datetime.datetime.strftime(date, format=\"%Y-%m-%d\")\n",
    "        tminus = 0\n",
    "\n",
    "        # initialize date dict, which will go into nightly_stats as {'date': {'stat': 'val', 'stat', 'val'}}\n",
    "        date_stats = defaultdict(int)\n",
    "\n",
    "        # start on the arrival date and move back\n",
    "        # to capture ALL reservations touching 'date' (and not just those that arrive on 'date')\n",
    "        for _ in range(max_los):\n",
    "\n",
    "            #\n",
    "            date_tminus = date - pd.DateOffset(tminus)\n",
    "\n",
    "            date_tminus_string = datetime.datetime.strftime(\n",
    "                date_tminus, format=\"%Y-%m-%d\"\n",
    "            )\n",
    "\n",
    "            mask = (\n",
    "                (df_dates.ArrivalDate == date_tminus_string)\n",
    "                & (df_dates.LOS >= 1 + tminus)\n",
    "                & (df_dates.IsCanceled == 0)\n",
    "            )\n",
    "\n",
    "            date_stats[\"RoomsSold\"] += len(df_dates[mask])\n",
    "            date_stats[\"RoomRev\"] += df_dates[mask].ADR.sum()\n",
    "\n",
    "            tmp = (\n",
    "                df_dates[mask][[\"ResNum\", \"CustomerType\", \"ADR\"]]\n",
    "                .groupby(\"CustomerType\")\n",
    "                .agg({\"ResNum\": \"count\", \"ADR\": \"sum\"})\n",
    "                .rename(columns={\"ResNum\": \"RS\", \"ADR\": \"Rev\"})\n",
    "            )\n",
    "\n",
    "            c_types = [\"Transient\", \"Transient-Party\", \"Group\", \"Contract\"]\n",
    "\n",
    "            if \"Transient\" in list(tmp.index):\n",
    "                date_stats[\"Trn_RoomsSold\"] += tmp.loc[\"Transient\", \"RS\"]\n",
    "                date_stats[\"Trn_RoomRev\"] += tmp.loc[\"Transient\", \"Rev\"]\n",
    "            if \"Transient-Party\" in list(tmp.index):\n",
    "                date_stats[\"TrnP_RoomsSold\"] += tmp.loc[\"Transient-Party\", \"RS\"]\n",
    "                date_stats[\"TrnP_RoomRev\"] += tmp.loc[\"Transient-Party\", \"Rev\"]\n",
    "            if \"Group\" in list(tmp.index):\n",
    "                date_stats[\"Grp_RoomsSold\"] += tmp.loc[\"Group\", \"RS\"]\n",
    "                date_stats[\"Grp_RoomRev\"] += tmp.loc[\"Group\", \"Rev\"]\n",
    "            if \"Contract\" in list(tmp.index):\n",
    "                date_stats[\"Cnt_RoomsSold\"] += tmp.loc[\"Contract\", \"RS\"]\n",
    "                date_stats[\"Cnt_RoomRev\"] += tmp.loc[\"Contract\", \"Rev\"]\n",
    "\n",
    "            tminus += 1\n",
    "\n",
    "        nightly_stats[date_string] = dict(date_stats)\n",
    "        date += delta\n",
    "\n",
    "    return pd.DataFrame(nightly_stats).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "local-timber",
   "metadata": {},
   "source": [
    "## Get `ResMadeDate` using TimeDelta on a pd.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-return",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_res['ResMadeDate'] = h1_res.ArrivalDate - h1_res['LeadTime'].map(datetime.timedelta)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
