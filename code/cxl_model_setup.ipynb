{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "moral-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "polish-colorado",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 60\n",
    "pd.options.display.max_columns = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "novel-duncan",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = pd.read_pickle(\"pickle/X1_cxl.pick\")\n",
    "y1 = pd.read_pickle(\"pickle/y1_cxl.pick\")\n",
    "\n",
    "X2 = pd.read_pickle(\"pickle/X2_cxl.pick\")\n",
    "y2 = pd.read_pickle(\"pickle/y2_cxl.pick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "collected-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = \\\n",
    "    train_test_split(X1, y1, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "willing-latest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SIMPLE LR Validation R^2 score was: 0.8347478781827259\n",
      "Test score:  0.2812031952071892\n",
      "\n",
      "RIDGE Validation R^2 score was: 0.3755678135507856\n",
      "\n",
      "LASSO Validation R^2 score was: 0.37543538760219597\n"
     ]
    }
   ],
   "source": [
    "def regularization(X, y):\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2,random_state=42)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=.25, random_state=42)\n",
    "    \n",
    "    # standardize data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train.values)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    \n",
    "    # logistic regression\n",
    "    lr = LogisticRegression(max_iter=500)\n",
    "    lr_model = lr.fit(X_train_scaled, y_train)\n",
    "    lr_score = lr_model.score(X_val_scaled, y_val)\n",
    "    \n",
    "    # ridge\n",
    "    ridge = RidgeCV(cv=5)\n",
    "    ridge_model = ridge.fit(X_train_scaled, y_train)\n",
    "    ridge_score = ridge_model.score(X_val_scaled, y_val)\n",
    "    \n",
    "    # lasso\n",
    "    lasso = LassoCV(cv=5)\n",
    "    lasso_model = lasso.fit(X_train_scaled, y_train)\n",
    "    lasso_score = lasso_model.score(X_val_scaled, y_val)\n",
    "    \n",
    "    print('\\nSIMPLE LR Validation F-1 score was:', lr_score)\n",
    "#     print('Feature coefficient results: \\n')\n",
    "    print('Test score: ', lr_model.score(X_test, y_test))\n",
    "#     for feature, coef in zip(X.columns, lr_model.coef_):\n",
    "#         print(feature, ':', f'{coef:.2f}') \n",
    "    \n",
    "    print('\\nRIDGE Validation F-1 score was:', ridge_score)\n",
    "#     print('Feature coefficient results: \\n')\n",
    "#     for feature, coef in zip(X.columns, ridge_model.coef_):\n",
    "#         print(feature, ':', f'{coef:.2f}') \n",
    "        \n",
    "    print('\\nLASSO Validation F-1 score was:', lasso_score)\n",
    "#     print('Feature coefficient results: \\n')\n",
    "#     for feature, coef in zip(X.columns, lasso_model.coef_):\n",
    "#         print(feature, ':', f'{coef:.2f}') \n",
    "    \n",
    "\n",
    "regularization(X1, y1)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polyphonic-vietnam",
   "metadata": {},
   "source": [
    "## XGBoost (Hotel 1): Hyperparameter Tuning with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "serial-unemployment",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = XGBClassifier(objective='binary:logistic',\n",
    "                          use_label_encoder=False,\n",
    "                          eval_metric='logloss',\n",
    "                          random_state=42,\n",
    "                          max_depth=5\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.08, 0.09, 0.1, 0.11, 0.12],\n",
    "    'n_estimators': [380, 390, 400, 410, 420, 475]\n",
    "}\n",
    "\n",
    "grid_search_1 = GridSearchCV(\n",
    "    estimator = estimator,\n",
    "    param_grid = params,\n",
    "    n_jobs=-1,\n",
    "    verbose=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "original-button",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competent-grade",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_xgb_fit_1 = grid_search_1.fit(X1_train, y1_train)\n",
    "print(\"The best parameters are: \\n\", grid_xgb_fit_1.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollow-victory",
   "metadata": {},
   "source": [
    "## XGBoost (Hotel 2): Hyperparameter Tuning with Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "chemical-halloween",
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = XGBClassifier(objective='binary:logistic',\n",
    "                          use_label_encoder=False,\n",
    "                          eval_metric='logloss',\n",
    "                          random_state=42,\n",
    ")\n",
    "\n",
    "# further tuning params\n",
    "params = {\n",
    "    'learning_rate': [0.08, 0.09, 0.1, 0.11, 0.12],\n",
    "    'n_estimators': [440, 450, 475, 500, 550]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search_2 = GridSearchCV(\n",
    "    estimator = estimator,\n",
    "    param_grid = params,\n",
    "    n_jobs=-1,\n",
    "    verbose=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "excess-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "marked-breakfast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   1 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done   3 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done   4 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done   5 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done   6 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done   7 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done   8 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  10 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done  11 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  12 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done  13 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  14 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  15 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done  19 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  20 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-1)]: Done  21 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done  22 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done  23 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=-1)]: Done  24 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done  27 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  31 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-1)]: Done  32 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done  35 tasks      | elapsed:  6.1min\n",
      "[Parallel(n_jobs=-1)]: Done  36 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=-1)]: Done  39 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done  40 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done  41 tasks      | elapsed:  7.9min\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done  43 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed:  8.2min\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done  47 tasks      | elapsed:  8.5min\n",
      "[Parallel(n_jobs=-1)]: Done  48 tasks      | elapsed:  8.6min\n",
      "[Parallel(n_jobs=-1)]: Done  49 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done  50 tasks      | elapsed:  9.6min\n",
      "[Parallel(n_jobs=-1)]: Done  51 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done  53 tasks      | elapsed:  9.8min\n",
      "[Parallel(n_jobs=-1)]: Done  54 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done  55 tasks      | elapsed:  9.9min\n",
      "[Parallel(n_jobs=-1)]: Done  56 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done  57 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done  58 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done  59 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done  60 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  61 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  62 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  63 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  64 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  65 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  66 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  67 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  68 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  69 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  70 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  71 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  72 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  73 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  75 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  76 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  78 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  79 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  80 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  81 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  83 tasks      | elapsed: 10.4min\n",
      "[Parallel(n_jobs=-1)]: Done  84 tasks      | elapsed: 10.4min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 736\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1188\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.8/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[1;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/metis/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid_xgb_fit_2 = grid_search_2.fit(X2_train, y2_train)\n",
    "print(\"The best parameters are: \\n\", grid_xgb_fit_2.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-florence",
   "metadata": {},
   "source": [
    "### First grid search results\n",
    "\n",
    "**H1 grid search setup**\n",
    "```\n",
    "estimator = XGBClassifier(objective='binary:logistic',\n",
    "                          use_label_encoder=False,\n",
    "                          eval_metric='logloss',\n",
    "                          random_state=42,\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.0001,0.01],\n",
    "    'max_depth': range(2,8,2),\n",
    "    'n_estimators': [200, 300, 400]\n",
    "}\n",
    "\n",
    "grid_search_1 = GridSearchCV(\n",
    "    estimator = estimator,\n",
    "    param_grid = params,\n",
    "    n_jobs=-1,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2,random_state=42)\n",
    "\n",
    "```\n",
    "\n",
    "**And the results**:\n",
    "```\n",
    "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
    "The best parameters are: \n",
    " {'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 400}\n",
    "CPU times: user 53.5 s, sys: 414 ms, total: 53.9 s\n",
    "Wall time: 1h 27min 17s\n",
    "```\n",
    "\n",
    "R^2 score: 0.830629056415377\n",
    "\n",
    "**H2 grid search setup was the same as H1 grid search setup (round 1)**\n",
    "\n",
    "**And the results**:\n",
    "\n",
    "```\n",
    "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
    "The best parameters are: \n",
    " {'learning_rate': 0.01, 'max_depth': 6, 'n_estimators': 400}\n",
    "CPU times: user 1min 37s, sys: 262 ms, total: 1min 38s\n",
    "Wall time: 1h 32min 4s\n",
    "```\n",
    "\n",
    "R^2 score: 0.8276818353712341\n",
    "\n",
    "### Second Round\n",
    "\n",
    "H1 setup & results\n",
    "```\n",
    "estimator = XGBClassifier(objective='binary:logistic',\n",
    "                          use_label_encoder=False,\n",
    "                          eval_metric='logloss',\n",
    "                          random_state=42,\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.005, 0.01, 0.05, 0.1],\n",
    "    'max_depth': range(5,6,7),\n",
    "    'n_estimators': [350, 400, 450]\n",
    "}\n",
    "\n",
    "grid_search_1 = GridSearchCV(\n",
    "    estimator = estimator,\n",
    "    param_grid = params,\n",
    "    n_jobs=-1,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2,random_state=42)\n",
    "\n",
    "# ---------RESULTS----------\n",
    "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
    "The best parameters are: \n",
    " {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 400}\n",
    "CPU times: user 40.9 s, sys: 325 ms, total: 41.2 s\n",
    "Wall time: 1h 37min 13s\n",
    "```\n",
    "\n",
    "R^2 score: 0.8514727908137794\n",
    "\n",
    "H2 results (setup the same as H1 round 2):\n",
    "\n",
    "```\n",
    "\n",
    "# SETUP SAME AS H1 ROUND 2\n",
    "\n",
    "# ---------RESULTS----------\n",
    "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
    "The best parameters are: \n",
    " {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 450}\n",
    "CPU times: user 1min 29s, sys: 236 ms, total: 1min 29s\n",
    "Wall time: 1h 41min 45s\n",
    "```\n",
    "R^2 score: 0.84904827933946\n",
    "\n",
    "### Round 3\n",
    "\n",
    "H1 setup different than H2 setup this time.\n",
    "\n",
    "H1 setup:\n",
    "```\n",
    "estimator = XGBClassifier(objective='binary:logistic',\n",
    "                          use_label_encoder=False,\n",
    "                          eval_metric='logloss',\n",
    "                          random_state=42,\n",
    "                          max_depth=5\n",
    ")\n",
    "\n",
    "params = {\n",
    "    'learning_rate': [0.08, 0.09, 0.1, 0.11, 0.12],\n",
    "    'n_estimators': [380, 390, 400, 410, 420, 475]\n",
    "}\n",
    "\n",
    "grid_search_1 = GridSearchCV(\n",
    "    estimator = estimator,\n",
    "    param_grid = params,\n",
    "    n_jobs=-1,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.2,random_state=42)\n",
    "\n",
    "# ---------RESULTS----------\n",
    "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
    "The best parameters are: \n",
    " {'learning_rate': 0.11, 'n_estimators': 475}\n",
    "CPU times: user 49.1 s, sys: 437 ms, total: 49.5 s\n",
    "Wall time: 4h 8min 47s\n",
    "```\n",
    "R^2 score: 0.854218671992012\n",
    "\n",
    "And H2 setup:\n",
    "\n",
    "```\n",
    "estimator = XGBClassifier(objective='binary:logistic',\n",
    "                          use_label_encoder=False,\n",
    "                          eval_metric='logloss',\n",
    "                          random_state=42,\n",
    ")\n",
    "\n",
    "# further tuning params\n",
    "params = {\n",
    "    'learning_rate': [0.08, 0.09, 0.1, 0.11, 0.12],\n",
    "    'n_estimators': [440, 450, 475, 500, 550]\n",
    "}\n",
    "\n",
    "\n",
    "grid_search_2 = GridSearchCV(\n",
    "    estimator = estimator,\n",
    "    param_grid = params,\n",
    "    n_jobs=-1,\n",
    "    verbose=100\n",
    ")\n",
    "\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2,random_state=42)\n",
    "\n",
    "# ---------RESULTS----------\n",
    "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
    "The best parameters are: \n",
    " {'learning_rate': 0.12, 'n_estimators': 550}\n",
    "CPU times: user 2min 8s, sys: 187 ms, total: 2min 8s\n",
    "Wall time: 5h 5min 44s\n",
    "```\n",
    "\n",
    "R^2 score: 0.8564225387621328"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "current-dairy",
   "metadata": {},
   "source": [
    "## XGB Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "unlike-coral",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8809286070893659"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb1 = XGBClassifier(n_estimators=475, learning_rate=0.11, eval_metric='logloss')\n",
    "xgb1.fit(X1_train, y1_train)\n",
    "xgb1.score(X1_test, y1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "governing-strap",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8588175973780411"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb2 = XGBClassifier(n_estimators=550, learning_rate=0.12, eval_metric='logloss')\n",
    "xgb2.fit(X2_train, y2_train)\n",
    "xgb2.score(X2_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-accident",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turned-sudan",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "familiar-fusion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accepted-dating",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'grid_xgb_fit_1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-f093c8ac6564>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrid_xgb1_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_xgb_fit_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgrid_xgb1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'grid_xgb_fit_1' is not defined"
     ]
    }
   ],
   "source": [
    "grid_xgb1_score = grid_xgb_fit_1.score(X1_test, y1_test)\n",
    "grid_xgb1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-genre",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_xgb2_score = grid_xgb_fit_2.score(X2_test, y2_test)\n",
    "grid_xgb2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cloudy-trainer",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_xgb_fit_1.to_pickle(\"pickle/h1_grid_result_1.pick\")\n",
    "grid_xgb_fit_2.to_pickle(\"pickle/h2_grid_result_1.pick\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "obvious-amazon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
